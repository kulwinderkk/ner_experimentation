
the risk of conflict of laws and creates difficulties, particularly in cross-border data flows and mutual legal assistance.
Collecting, sharing and selling digital data, in particular personal data, has both positive and negative human rights implications. Practices such as targeted advertising, content monitoring, private and public surveillance, spying, data collection for criminal investigations, internet filtering, use of biometric data, etc. can endanger privacy and freedom of expression. But digital data and AI can also contribute to improving the human condition. Thus, it is necessary to steer regulation towards a virtuous use of data.
Key commitments
-Data should be defined and categorized more precisely (personal data, sensitive data, security data, etc.) to adapt their legal regime according to their nature and use. Many efforts have been made in the field of personal data protection but many other data should also be regulated.
-With regard to personal data, the principles set out in the GDPR offer standards of protection which could be extended internationally to facilitate the circulation of data while preserving the protection of individuals. However, the interpretation of these standards needs to be harmonized in order to avoid conflicts of extraterritorial laws and regulatory fragmentation.
-In view of the evolution of the uses of data, whether for commercial or surveillance purposes, by private or public actors, the personal data protection regime should be refocused on the protection of privacy, which is its foundation, and no longer be developed as an autonomous regime, whose existence would be justified solely for commercial or security purposes.
-It is important to limit the risks of conflicts of law resulting from the extraterritorial scope of national laws by developing standards or even rules of international law.
-Data protection regimes should be developed to improve the human condition, reduce the digital divide, and facilitate the achievement of the SDGs.
Apply human rights online
Digital activities should not be implemented without taking into account their impact on human rights, the rule of law and the democratic values enshrined in the UN Charter and related legal instruments. Business innovation concerns should be matched with the systematic use of impact assessments and critical risk assessments when developing technological tools and digital processes that may infringe on human rights. Similarly, national security concerns or public order considerations should not justify disproportionate infringements on individual rights.
To date, there is no specific framework for digital activities that is truly universal in scope, covering, for example, the protection of personal data, automated decision-making processes or online expression. The lack of a unique framework is likely to be leveraged by some States in order to exploit digital tools for the purpose of monitoring individuals and restricting their rights. Yet, despite the lack of a universal digital-specific instrument, resorting to pre-existing legal instruments is a reliable way to protect individuals and community's rights in the digital sphere.
Indeed, in practice, a majority of United Nations Member States recognize the application of pre-existing rules of international law in the digital sphere, including those derived from international law instruments (United Nations Charter, International Covenants of 1966, regional charters for the protection of human rights, etc.). International human rights law is the most obvious and most visible way of addressing practices on the Internet, whether it be to regulate the activities of public actors (States, local authorities, international organizations) or those of private actors (companies, non-profit
 6