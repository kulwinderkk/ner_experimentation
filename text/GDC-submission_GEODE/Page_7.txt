
organizations). The reassertion of the States' positive obligations in this respect appears particularly necessary in the face of the infringements caused by private actors.
In this respect, it would seem vital for the international community to recognize that human rights, as enshrined in the relevant legal instruments, apply in the digital sphere, particularly online. The statements of actors refuting this vision are at odds with the actual practice, including international and regional case law.
Key commitments:
-States should recognize that human rights, as enshrined in the relevant legal instruments, apply in the digital sphere.
-Impact assessments processes and critical risk assessments should be implemented when developing technological tools and digital processes that may infringe on human rights.
-States should refrain from restricting individuals' legitimate access to technological tools.
Accountability for discrimination and misleading content
Digital platforms are, at the same time, spaces for the promotion of human rights and democratic processes and the tools that may lead to their erosion.
Initially, these platforms were mostly recreational or informative in nature. Over time, they have acquired a critical role as spaces for the civil society to mobilize or to expose regimes that do not respect fundamental rights. Today, they have become an indispensable tool for almost half of mankind: close to three billion individuals use the services offered by tech companies, most notably social media. However, the continuous stream of content published by users generates numerous abuses that can only be addressed by moderation mechanisms (deleting content, marking it, downgrading it or evicting users). Discriminatory comments, calls to hatred or violence, defamation, privacy breaches or disinformation operations are among the harmful behaviors that platforms have to regulate in real time.
However, acting against unlawful content comes with challenges. The first is that content moderation is carried out by companies on the basis of specific standards that do not always comply with laws and regulations, particularly in terms of human rights, and that are applied on an international scale without adapting to local cultural contexts. The second is that, when it is not automated, the moderation activity is entrusted to employees or subcontractors who may be based in remote regions of the world and who are generally ill-equipped to determine when content is legitimate or not.
These two factors can lead to zealous or hasty moderation practices, likely to constitute an infringement of freedom of expression. On the other hand, some content that should be moderated because it violates human rights or undermines public order or democratic processes remains online as a result of commercial decisions. States should take the necessary measures, in accordance with international law, to oversee the moderation activities of platforms and make them accountable. It is essential that content violating fundamental rights be treated according to due diligence standards and that freedom of expression not be subject to disproportionate restrictions.
Key commitments:
-States should address disinformation and misinformation practices in coordination with companies, civil society and users.
 7