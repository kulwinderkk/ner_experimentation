
-States should take the necessary measures, in accordance with international law and their national laws, to oversee the moderation activities of platforms and make them accountable for their shortcomings.
-Online moderation policies should always be interpreted and implemented by companies and State actors in accordance with relevant international human rights instruments.
-States should not misuse the prevention of disinformation as a pretext for disproportionate restrictions on freedom of expression
Regulation of artificial intelligence
No longer only embedded in products and industrial systems, artificial intelligence (AI) has recently made a breakthrough in our everyday life through becoming accessible and directly usable by end-users. In doing so, computing power and algorithms are more than ever processes and tools that are impacting our lives, our economies and our democracies. AI can bring innovation and progress for individuals and democracy, by offering new modes of expression and production. Considering the global challenges that our societies are facing, AI provides new means to address them, particularly in the domains of public health and the environment. AI-based products and services can also play a role in strengthening the rule of law and the enforcement of international law, including through monitoring and evaluating the implementation of States' international commitments.
However, the development of AI is not without risks to the fundamental rights and freedoms of individuals, the rule of law, and international development. Indeed, AI learning models require large volumes of data, which process can disregard the legal protection attached to the data. Biases from data processing are multiplied, creating new and often underestimated risks of discrimination. In a context where non-state actors, especially companies, are the main holders of this data, the under-representation of certain regions of the world and the concentration of capacities in the hands of a few actors present a risk for cultural and social diversity and international development. Thus AI contributes to the reinforcement of the digital divide and the confinement of the individual through the prism of data. Finally, because of its very operating processes, the impact of AI on the environment is becoming a major issue that remains unevaluated.
The multiplicity of AI uses undeniably constitutes a difficulty when tackling its regulation. The unknowns accompanying its consequences on societies and fundamental rights must be seen as alerts guiding each step of the development of a technology, a product or a service based on AI. The open sourcing of AI systems and the conditions for their reuse should be given particular attention in order to encourage development that is consistent with international law, and in particular international human rights law. As such, AI thus constitutes a new area in which States' positive human rights obligations find their way, and in a potentially new dimension.
In recent years, numerous normative initiatives have emerged to regulate the development and use of AI. They tend to set a minimum of commitments for AI, regardless of sector-specific needs. Yet, sectoral approaches might be needed to better tackle the challenges. Similarly, an autonomous approach to AI should not lead to its omission from forums dealing with other subjects, notably cybersecurity and the environment. In both cases, the ethical approach is not sufficient in itself. It is also interesting to note that despite an ethical approach to AI regulation, the content of the instruments discussed is often very legal. The choice of legal over ethical should be preserved.
Key commitments:
-Any development of an AI product or service should only be conducted after a careful risk assessment and should be compatible with human rights frameworks. In case of high or
 8