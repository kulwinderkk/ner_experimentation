
undetermined risks for human rights, the development of an AI product or service should be prohibited or only conducted under high scrutiny from public authorities.
-States should set up independent authorities tasked with overseeing the development and uses of AI by state and non-state authorities. Those authorities should be given appropriate means and resources. They should not exclude the recourse to judicial authorities in case rights and obligations are being abused.
-Next to the international consensus on accountability, responsibility and transparency as core principles guiding the development and use of AI, States and non-state actors should cooperate on the concrete implementation of these principles through the exchange of best practices in order to engage in more precise regulation.
-Independent research on the biases and negative impact of AI technologies and services should be conducted. State and non-state actors should thus cooperate with researchers to develop evidence-based research.
Digital commons as a global public / Good Internet governance
As early as the World Summit on the Information Society in Geneva and Tunis (2003 and 2005), stakeholders called for multilateral and multi-stakeholder governance. These governance modalities have constantly been called for (Net Mundial Declaration, SÃ£o Paulo, 2014; UNGGE and United Nations OEWG reports on international cybersecurity) but have not, however, made it possible to respond to the challenges of the digital era or to prevent deadlocks in international negotiations.
The issues at stake in international negotiations are essentially geopolitical but also have a legal impact. States are competing to impose different conceptions of Internet governance: some of them see the digital sphere as an essentially economic opportunity, some focus on human development and others give priority to state security. These conflicting conceptions hinder the application and adaptation of international law to digital activities. The geopolitical challenges surrounding Internet governance also affect the model of cyberspace itself, contributing to its fragmentation, the integration or non-integration of infrastructures, the inclusion or exclusion of the informational dimension. Internet governance depends on the way in which the Internet and, more generally, the digital object are described: critical infrastructure, global risk, common good. Each of these qualifications entails the application of a particular legal regime and the involvement of specific governance actors. Thinking of the Internet as a common good requires us to consider the global management of its resources, namely data, on the model of the International Seabed Authority, for example. But unlike other international regimes for managing the commons, the resources constituted by digital data are not limited; on the contrary, they are growing exponentially. Existing regimes must therefore be adapted to the specificities of digital data.
The consequences of these conceptual oppositions are manifold: States cannot reach a consensus on what good governance should be to ensure the security and stability of cyberspace; the logic of coalition between certain States is reinforced, contributing to a greater fragmentation of regulation and the exclusion of certain States from the scope of the discussion; certain issues, such as cybersecurity, cannot be settled or are settled in a roundabout way from an economic angle, for example (see the OECD's work on this point).
Key commitments:
-Strengthen multilateralism by including developing States and by promoting dialogue between the different conceptions of cyberspace and applicable international law.
-Implementing in a more concrete way multistakeholderism through the notion of co-regulation: the balance between stakeholders is not necessarily the same according to the subjects to be regulated; the modalities of cooperation between public and private actors may vary according to the fields of action.
 9