
politicians and human rights defenders to block and document the harassment they receive on social media platforms like Twitter.
Apply our AI innovations to continually improve Google itself as a leading organization, and to share what we learn with other organizations, including customers, governments, non-governmental organizations and international organizations. Key areas of focus include :
● Leveraging AI to achieve industry-leading safety and cybersecurity across all our products and services.
● Applying AI to improve our own productivity and operations across all functions.
● Using AI to help realize bold ambitions in climate and sustainability.
As with any transformational technology, AI comes with complexities and risks, and these will change over time. As an evolving technology, its ever-changing capabilities and uses create potential for misapplication, misuse, and unintended or unforeseen consequences. We are taking a proactive approach to understand the evolving complexities and risks as AI advances, deployment grows, and use expands, while continuing to learn from users and the wider community. We urge other companies operating in this space to do the same.
We recognize the harms that these failures can cause, especially for different communities and contexts across the globe, and a key aim of the Global Digital Compact could be to identify best practices for mitigating the above risks to increase trust, ensure safe and inclusive user experiences, and enable AI to fully benefit people, planet and society.
Our approach to Responsible AI
Given its risks and complexities, we believe that we as a global company must pursue AI responsibly. As leaders in AI, we must lead not only in state-of-the-art AI technologies, but also in state-of-the-art responsible AI. In 2018, we were one of the first companies to articulate AI Principles that put beneficial use, users, safety, and avoidance of harms above business considerations, and we have pioneered many best practices, like the use of model and data cards now widely used by others. A year later in 2019, Organization for Economic Cooperation and Development (OECD) Member States agreed on their own AI principles, many of which mirrored our own.
While we continue to push the frontiers of innovation in AI, we continue to learn from users, other researchers, affected communities, and our experiences. As a result, we are continually refining our approaches to ensure that the above considerations are incorporated in all we do and address issues as they arise. We aim to work in meaningful ways that help shape but do not slow down innovation that can benefit people, planet and society.
Why a collective approach to responsible AI is needed-and how the UN Global Digital Compact can help :
We believe that getting AI right requires a collective effort at a global scale. We do not have all the answers, but our experience so far suggests that everyone involved in AI (researchers,